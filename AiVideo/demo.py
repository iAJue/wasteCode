from moviepy.video.io.VideoFileClip import VideoFileClip
import os

def time_to_seconds(time_str):
    """Convert time in format h:m:s.ms to seconds."""
    h, m, s = map(float, time_str.split(':'))
    return h * 3600 + m * 60 + s

# 定义视频文件路径和输出文件夹路径
video_file_path = 'path_to_your_video_file.mp4'  # 替换为你的视频文件路径
output_folder = 'output_segments'

# 创建输出文件夹
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# 定义分段信息
segments = [
    {"start": "0:00:19.06", "end": "0:01:32.40", "narration": "欢迎来到《花咲くいろは》！故事开篇，我们的女主松前绪花正过着平凡的日常生活。她和妈妈的对话就像是普通家庭的“战争”。她的妈妈忙得不可开交，而绪花则在一旁展示她的小大人模样。"},
    {"start": "0:01:32.76", "end": "0:03:16.36", "narration": "剧情突然反转，绪花接到妈妈的电话，得知要去外婆家住。绪花一脸懵圈，但也隐隐期待着这场“说走就走的旅行”。妈妈这波操作真是让人措手不及啊！"},
    {"start": "0:03:16.36", "end": "0:06:13.18", "narration": "哦，原来是因为欠了一屁股债！妈妈决定来一场夜逃，绪花虽然心里一万个不明白，但还是配合妈妈的行动。她内心戏丰富，仿佛已经把这次逃亡当成了一场冒险。"},
    {"start": "0:06:13.18", "end": "0:07:19.22", "narration": "离别总是伤感的，绪花和好友阿孝告别。阿孝突然告白：“我喜欢你！”绪花表示：你在说啥呢？这突然的告白真是让人措手不及，阿孝，你这一招是学来的吧？"},
    {"start": "0:07:19.22", "end": "0:09:59.08", "narration": "绪花踏上了前往外婆家的旅程，心里五味杂陈。途中，她遇到了一些新奇的人和事，这一切都预示着她将迎来一段不平凡的生活。绪花心想，这就像是一场真人秀，我准备好了！"},
    {"start": "0:09:59.08", "end": "0:11:17.88", "narration": "哇哦，终于见到外婆了！不过外婆的态度比冰山还冷：“从现在起你就是这里的佣工。”绪花心里OS：这什么鬼？我不是你外孙女吗？新生活的挑战正式开始！"},
    {"start": "0:11:17.88", "end": "0:15:02.51", "narration": "绪花努力适应新环境，但困难重重。她认识了新同事，每个人都有自己的个性和故事。绪花在这过程中逐渐学会如何与他们相处，当然，也有不少搞笑的瞬间。"},
    {"start": "0:15:02.51", "end": "0:17:01.81", "narration": "绪花在工作中不断遇到挫折，但她没有放弃。她的勤奋和坚韧逐渐赢得了大家的认可。看着她一点点成长，真是既搞笑又感动。"},
    {"start": "0:17:01.81", "end": "0:20:56.68", "narration": "绪花与外婆的矛盾爆发，外婆对她的严格要求让她感到压力山大。尽管如此，绪花仍然坚持下去，希望能通过自己的努力改变外婆的看法。这段剧情简直是“婆媳大战”的经典再现。"},
    {"start": "0:20:56.68", "end": "0:22:31.75", "narration": "面对外婆的批评，绪花表现出了坚定和决心。她请求外婆再给她一次机会，并愿意承担责任。绪花的表现让人刮目相看，看来她已经不是那个小女孩了。"}
]

# 加载视频文件
video = VideoFileClip(video_file_path)

# 分割视频并保存片段
for i, segment in enumerate(segments):
    start_time = time_to_seconds(segment["start"])
    end_time = time_to_seconds(segment["end"])
    output_file_path = os.path.join(output_folder, f'segment_{i+1}.mp4')
    
    # 如果文件已存在，跳过该片段
    if os.path.exists(output_file_path):
        print(f"文件 {output_file_path} 已存在，跳过剪辑。")
        continue
    
    clip = video.subclip(start_time, end_time)
    clip.write_videofile(output_file_path, codec='libx264')
    print(f"片段 {i+1} 已保存为 {output_file_path}")
    
print("视频分割完成！")




# 方法一：
# 先通过字幕文件进行分析，给视频分出剧情桥段，给每一个桥段编写一份解说的文稿，同时也确定了桥段的开始和结束时间，然后根据这些时间进行视频分割。
# 在通过计算机视觉系统和自然语言处理技术对视频文件进行处理，保证视频的画面和字幕的解说内容一致，最后将分割好的视频片段和字幕文件进行合并，生成一份完整的解说视频。
# 至于为什么要先对视频的桥段先进行一次裁剪视频是因为尽可能的保证视频匹配的精准度和效率方面的问题。

# 难点在于计算机视觉系统用来分析视频的内容，需要训练相应的模型，而且也消耗很大的算力，所以需要使用GPU进行训练，同时自然语言处理技术也需要训练相应的模型，也需要消耗很大的算力，所以也需要使用GPU进行训练。
# 所以在训练模型之前需要先准备好GPU环境，同时需要准备好训练数据，训练数据需要包含视频文件和字幕文件，同时还需要有对应的标签数据，标签数据需要包含视频文件和字幕文件对应的桥段信息。
# 最后在训练模型的时候需要使用GPU进行训练，同时需要使用多线程和多进程的方式进行训练，以提高训练的效率。

# 关于识别视频画面这个点我们也可以使用OCR的技术进行一个识别，识别视频的字幕内容，当不推荐这个那还不如直接分析字幕文件呢，而且万一视频没有字幕呢
# 所以，通过OCR识别的话，去识别视频画面中的场景人物进行一个匹配操作，但这同时也需要进行一个模型的训练问题。


# 方法二：
# 通过OCR这个点，我们想到，既然我们的解说的文稿都是自己那字幕文件进行一个分析的话，那我们的画面匹配问题为何不也自己拿字幕文件分析呢。
# 既然他都能直接分析字幕进能拿到文稿，我们一样能通过字幕进行一个画面的匹配
# 当这个其中也有一个问题进是，如果视频是一个无声的视频，进无法进行一个操作
# 另外 ，如果视频说话的是这一个人，而镜头却是在另一个场景或者人的身上，这就会导致解说的内容是在这个画面，当我们实际在解说的是这画面字幕所说的内容。
# 不过这个问题也不是很大，因为我们本身是对字幕文件解析之后在作出的一个解说文稿，所以在字幕抵达的时候，也不会产生太大的不合理。